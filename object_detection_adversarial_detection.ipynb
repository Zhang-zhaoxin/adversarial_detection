{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Demo\n",
    "Welcome to the object detection inference walkthrough!  This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from distutils.version import StrictVersion\n",
    "import PIL.Image\n",
    "import random\n",
    "#config = tf.ConfigProto() \n",
    "#config.gpu_options.allow_growth = True \n",
    "#sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "# from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_CKPT` to point to a new .pb file.  \n",
    "\n",
    "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "#MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "# MODEL_NAME = 'object_detection/faster_rcnn_resnet101_coco_2018_01_28'\n",
    "MODEL_NAME = 'object_detection/faster_rcnn_inception_v2_coco_2017_11_08'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "# PATH_TO_FROZEN_GRAPH = 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\models\\\\research\\\\object_detection\\\\faster_rcnn_inception_v2_coco_2017_11_08\\\\frozen_inference_graph.pb'\n",
    "PATH_TO_FROZEN_GRAPH = 'G:\\\\zzx\\models\\\\research\\\\object_detection\\\\faster_rcnn_inception_v2_coco_2017_11_08\\\\frozen_inference_graph.pb'\n",
    "\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "# PATH_TO_LABELS = 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\models\\\\research\\\\object_detection\\\\data\\\\mscoco_label_map.pbtxt'\n",
    "PATH_TO_LABELS = 'G:\\\\zzx\\\\models\\\\research\\\\object_detection\\\\data\\\\mscoco_label_map.pbtxt'\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opener = urllib.request.URLopener()\n",
    "# opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "# tar_file = tarfile.open(MODEL_FILE)\n",
    "# for file in tar_file.getmembers():\n",
    "#   file_name = os.path.basename(file.name)\n",
    "#   if 'frozen_inference_graph.pb' in file_name:\n",
    "#     tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detection_graph = tf.Graph()\n",
    "# with detection_graph.as_default():\n",
    "#   od_graph_def = tf.GraphDef()\n",
    "#   with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "#     serialized_graph = fid.read()\n",
    "#     od_graph_def.ParseFromString(serialized_graph)\n",
    "#     tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'gfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f8645a91d509>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabel_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_labelmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH_TO_LABELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_label_map_to_categories\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_num_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_display_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcategory_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_category_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\zzx\\models\\research\\object_detection\\utils\\label_map_util.py\u001b[0m in \u001b[0;36mload_labelmap\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mStringIntLabelMapProto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m   \"\"\"\n\u001b[1;32m--> 138\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[0mlabel_map_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mlabel_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstring_int_label_map_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStringIntLabelMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'gfile'"
     ]
    }
   ],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "#category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# For the sake of simplicity we will use only 2 images:\n",
    "# image1.jpg\n",
    "# image2.jpg\n",
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "# PATH_TO_TEST_IMAGES_DIR = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\models\\\\picture\\\\objectdetect\\\\adv-*\"\n",
    "PATH_TO_TEST_IMAGES_DIR = \"G:\\\\zzx\\\\models\\\\picture\\\\objectdetect\\\\adv-*\"\n",
    "#TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 2) ]\n",
    "TEST_IMAGE_PATHS = glob.glob(PATH_TO_TEST_IMAGES_DIR)\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "print(TEST_IMAGE_PATHS)\n",
    "\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "\n",
    "checkpoint_path=os.path.join(PATH_TO_CKPT)\n",
    "reader=pywrap_tensorflow.NewCheckpointReader(checkpoint_path)\n",
    "var_to_shape_map=reader.get_variable_to_shape_map()\n",
    "for key in var_to_shape_map:\n",
    "    print('tensor_name:' ,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_path=\"G:\\\\zzx\\\\models\\\\research\\\\object_detection\\\\test_images\\\\1.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image=image.resize((1920,1080))\n",
    "\n",
    "\n",
    "# # the array based representation of the image will be used later in order to prepare the\n",
    "# # result image with boxes and labels on it.\n",
    "image_np = load_image_into_numpy_array(image.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#定义类adv_model 封装生成对抗样本的功能\n",
    "class adv_model():\n",
    "    def __init__(self):\n",
    "        self.graph = tf.Graph()\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "        self.tensor_dict = {}\n",
    "        self.patch_shape=(1, 1080, 1920, 3)\n",
    "        self._make_model_and_ops()\n",
    "            \n",
    "\n",
    "    def _make_model_and_ops(self):\n",
    "        \n",
    "        with self.sess.graph.as_default():\n",
    "            \n",
    "            # Tensors are post-fixed with an underscore!\n",
    "            self.image_input_ = tf.placeholder(tf.float32, shape=self.patch_shape, name='image_input_placeholder')\n",
    "            self.patch_ = tf.get_variable('patch', self.patch_shape, dtype=tf.float32, initializer=tf.zeros_initializer)\n",
    "            self.patch_placeholder_ = tf.placeholder(dtype=tf.float32, shape=self.patch_shape, name='patch_placeholder')\n",
    "            self.assign_patch_ = tf.assign(self.patch_, self.patch_placeholder_)\n",
    "                \n",
    "            #self.clipped_patch_ = tf.tanh(patch_)\n",
    "            patched_input_ = self.patch_+self.image_input_/255.0\n",
    "            #patched_input_ = self.clipped_patch_+self.image_input_placeholder\n",
    "            #高级阶段函数 可以结算梯度\n",
    "            #This operation has a gradient and thus allows for training min and max values.\n",
    "            #https://tensorflow.google.cn/api_docs/python/tf/quantization/fake_quant_with_min_max_vars\n",
    "            self.patched_input_ = tf.fake_quant_with_min_max_vars(patched_input_*255.0, min=0, max=255)\n",
    "            \n",
    "            # Create placeholders for NMS RPN inputs\n",
    "            self.rpn_nms_bboxes_placeholder_ = tf.placeholder(tf.float32, shape=(None, 4), name='rpn_nms_bboxes')\n",
    "            self.rpn_nms_indices_placeholder_ = tf.placeholder(tf.int32, shape=(None), name='rpn_nms_indices')\n",
    "            \n",
    "            \n",
    "            #image_tensor:0到输出之间存在无法计算梯度的op，因此需要直接操作Preprocessor/map/TensorArrayStack/TensorArrayGatherV3:0\n",
    "            def create_graph(dirname):\n",
    "                with tf.gfile.GFile(dirname, 'rb') as f:\n",
    "                    graph_def = self.sess.graph_def\n",
    "                    graph_def.ParseFromString(f.read())\n",
    "\n",
    "                    _ = tf.import_graph_def(graph_def, name='adv_model',\n",
    "                        input_map={\n",
    "                           'Preprocessor/map/TensorArrayStack/TensorArrayGatherV3:0':self.patched_input_,\n",
    "                           'Reshape_7:0':self.rpn_nms_bboxes_placeholder_,\n",
    "                           'Reshape_8:0':self.rpn_nms_indices_placeholder_\n",
    "                            }\n",
    "                                           )\n",
    "\n",
    "            create_graph(PATH_TO_FROZEN_GRAPH) \n",
    "            \n",
    "            # Recreate tensors we just replaced in the input_map\n",
    "            self.rpn_nms_bboxes_ = tf.reshape( self.graph.get_tensor_by_name('adv_model/Reshape_6:0'), \n",
    "                                              self.graph.get_tensor_by_name('adv_model/stack_3:0'), \n",
    "                                              name='adv_model/Reshape_7')\n",
    "            self.rpn_nms_indices_ = tf.reshape(self.graph.get_tensor_by_name('adv_model/mul_1:0'), \n",
    "                                               self.graph.get_tensor_by_name('adv_model/Reshape_8/shape:0'),\n",
    "                                               name='adv_model/Reshape_8') \n",
    "\n",
    "            # Second-stage Class Loss\n",
    "            self.second_stage_cls_scores_ = self.graph.get_tensor_by_name('adv_model/SecondStagePostprocessor/convert_scores:0')\n",
    "            second_stage_cls_logits_ = self.graph.get_tensor_by_name('adv_model/SecondStagePostprocessor/scale_logits:0')\n",
    "            self.second_stage_cls_labels_ = tf.placeholder(tf.float32, shape=second_stage_cls_logits_.shape, name='second_stage_cls_labels')\n",
    "            second_stage_cls_losses_ = tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.reshape(self.second_stage_cls_labels_, (-1, self.second_stage_cls_labels_.shape[2])),\n",
    "                                                                                      logits=tf.reshape(second_stage_cls_logits_, (-1, second_stage_cls_logits_.shape[2]))) \n",
    "            second_stage_cls_losses_ = tf.reshape(second_stage_cls_losses_, (-1, self.second_stage_cls_labels_.shape[1]))\n",
    "            second_stage_cls_losses_ = tf.divide(second_stage_cls_losses_, tf.to_float(self.second_stage_cls_labels_.shape[1]))\n",
    "            self.second_stage_cls_loss_ = tf.reduce_sum(second_stage_cls_losses_)\n",
    "            \n",
    "            \n",
    "            # Second-stage bounding boxes\n",
    "            self.second_stage_loc_bboxes_ = self.graph.get_tensor_by_name('adv_model/SecondStagePostprocessor/Reshape_4:0')\n",
    "           \n",
    "            # Sum of weighted losses\n",
    "            self.loss_ = self.second_stage_cls_loss_\n",
    "\n",
    "            # Train our attack by only training on the patch variable\n",
    "            #self.train_op_ = tf.train.GradientDescentOptimizer(0.1).minimize(self.loss_, var_list=[patch_])\n",
    "            self.train_op_ = tf.train.AdamOptimizer(0.01).minimize(self.loss_, var_list=[self.patch_])\n",
    "            \n",
    "            # 初始化参数  非常重要 Adam的参数也需要这样初始化 GradientDescent可以省略这一步\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "                \n",
    "            #初始化\n",
    "            self.sess.run(self.assign_patch_, {self.patch_placeholder_: np.zeros(self.patch_shape)})\n",
    "\n",
    "    def inference_rpn(self, images):\n",
    "        feed_dict = { self.image_input_: images }\n",
    "        \n",
    "        tensors = [self.rpn_nms_bboxes_,\n",
    "                   self.rpn_nms_indices_ ]\n",
    "\n",
    "        rpn_nms_bboxes, rpn_nms_indices = self.sess.run(tensors, feed_dict)\n",
    "        \n",
    "        return rpn_nms_bboxes, rpn_nms_indices\n",
    "\n",
    "    #预测并绘图\n",
    "    def inference_draw(self, images):\n",
    "\n",
    "        patched_imgs, second_stage_cls_scores, second_stage_loc_bboxes = self.inference(images)\n",
    "        patched_imgs = patched_imgs.astype(np.uint8)\n",
    "        \n",
    "        \n",
    "        scores = second_stage_cls_scores[0]\n",
    "        bboxes = second_stage_loc_bboxes[0]\n",
    "        \n",
    "        sorted_classes = np.argsort(scores[:, 1:], axis=1)\n",
    "        sorted_scores = scores[:, 1:].copy()\n",
    "        sorted_bboxes = bboxes.copy()\n",
    "        \n",
    "        \n",
    "#         print(\"sorted_classes\")\n",
    "#         print(sorted_classes.shape)\n",
    "#         print(sorted_classes)\n",
    "\n",
    "        for i, ordering in enumerate(sorted_classes):\n",
    "            sorted_scores[i, :] = scores[i, ordering+1]\n",
    "            sorted_bboxes[i, :] = bboxes[i, ordering, :]\n",
    "\n",
    "        sorted_classes += 1\n",
    "\n",
    "        \n",
    "        \n",
    "        # Visualization of the results of a detection.\n",
    "        show_image_np=vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              patched_imgs[0].copy(),\n",
    "              sorted_bboxes[:, -1, :],\n",
    "              sorted_classes[:, -1].astype(np.int32),\n",
    "              sorted_scores[:, -1],\n",
    "              category_index,\n",
    "              use_normalized_coordinates=False,\n",
    "              max_boxes_to_draw=5,\n",
    "              min_score_thresh=0.2,\n",
    "              line_thickness=2,\n",
    "              skip_scores=True,\n",
    "              skip_labels=False)\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.imshow(show_image_np)\n",
    "#         PIL.Image.fromarray(patched_imgs[0].copy()).save('perturbation.jpg')\n",
    " \n",
    "        return None\n",
    "        \n",
    "\n",
    "    def inference(self, images):\n",
    "        rpn_nms_bboxes, rpn_nms_indices = self.inference_rpn(images)\n",
    "\n",
    "        feed_dict = { self.image_input_: images,\n",
    "                      self.rpn_nms_bboxes_placeholder_: rpn_nms_bboxes,\n",
    "                      self.rpn_nms_indices_placeholder_: rpn_nms_indices }\n",
    "\n",
    "        tensors = [ self.patched_input_,\n",
    "                    self.second_stage_cls_scores_,\n",
    "                    self.second_stage_loc_bboxes_ ]\n",
    "\n",
    "        patched_imgs, second_stage_cls_scores, second_stage_loc_bboxes = self.sess.run(tensors, feed_dict)\n",
    "        patched_imgs = patched_imgs.astype(np.uint8)\n",
    "        \n",
    "        return patched_imgs, second_stage_cls_scores, second_stage_loc_bboxes   \n",
    "\n",
    "    \n",
    "    \n",
    "    def train_step(self, images, second_stage_cls_labels):\n",
    "        \n",
    "        rpn_nms_bboxes, rpn_nms_indices = self.inference_rpn(images)\n",
    "        \n",
    "        feed_dict = { \n",
    "                      self.image_input_: images,\n",
    "                      self.second_stage_cls_labels_: second_stage_cls_labels,\n",
    "                      self.rpn_nms_bboxes_placeholder_: rpn_nms_bboxes,\n",
    "                      self.rpn_nms_indices_placeholder_: rpn_nms_indices, }\n",
    "        \n",
    "        \n",
    "        tensors = [ self.train_op_,\n",
    "                    self.loss_]\n",
    "\n",
    "        train_op, loss= self.sess.run(tensors, feed_dict)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def get_patch(self):\n",
    "        \n",
    "        patch=self.sess.run(self.patch_)\n",
    "        patch = np.round(patch[0]*255.0).astype(np.uint8)\n",
    "        \n",
    "        return patch\n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adv_model_instance = adv_model()\n",
    "# image_path=\"G:\\\\zzx\\\\models\\\\research\\\\object_detection\\\\test_images\\\\4.jpg\"\n",
    "# image = Image.open(image_path).convert(\"RGB\")\n",
    "# image=image.resize((1920,1080))\n",
    "\n",
    "\n",
    "# # # the array based representation of the image will be used later in order to prepare the\n",
    "# # # result image with boxes and labels on it.\n",
    "# image_np = load_image_into_numpy_array(image.copy())\n",
    "\n",
    "\n",
    "#从person 1 变为horse 19 \n",
    "TARGET_CLASS = 19\n",
    "FROM_CLASS = 3 \n",
    "\n",
    "def create_target_labels(scores, from_class, to_class):\n",
    "    target_labels = np.zeros_like(scores)\n",
    "    classes = np.argmax(scores[:, :, 1:], axis=2)+1\n",
    "    #print(classes)\n",
    "    \n",
    "    for i, _ in enumerate(classes):\n",
    "        for j, cls in enumerate(classes[i]):\n",
    "            cls = to_class # Just perturb all of them!\n",
    "            target_labels[i, j, cls] = 1 # set to 1 for targeted attack\n",
    "\n",
    "    return target_labels\n",
    "\n",
    "\n",
    "_, scores, _  = adv_model_instance.inference(np.expand_dims(image_np.copy(),0))\n",
    "#print(scores)\n",
    "#print(scores.shape)\n",
    "\n",
    "target_labels = create_target_labels(scores, FROM_CLASS, TARGET_CLASS)\n",
    "#print(target_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#开始迭代求解 \n",
    "#@param [\"1: person\", \"2: bicycle\", \"3: car\", \"4: motorcycle\", \"5: airplane\", \"6: bus\", \"7: train\", \"8: truck\", \"9: boat\", \"10: traffic light\", \"11: fire hydrant\", \"13: stop sign\", \"14: parking meter\", \"15: bench\", \"16: bird\", \"17: cat\", \"18: dog\", \"19: horse\", \"20: sheep\", \"21: cow\", \"22: elephant\", \"23: bear\", \"24: zebra\", \"25: giraffe\", \"27: backpack\", \"28: umbrella\", \"31: handbag\", \"32: tie\", \"33: suitcase\", \"34: frisbee\", \"35: skis\", \"36: snowboard\", \"37: sports ball\", \"38: kite\", \"39: baseball bat\", \"40: baseball glove\", \"41: skateboard\", \"42: surfboard\", \"43: tennis racket\", \"44: bottle\", \"46: wine glass\", \"47: cup\", \"48: fork\", \"49: knife\", \"50: spoon\", \"51: bowl\", \"52: banana\", \"53: apple\", \"54: sandwich\", \"55: orange\", \"56: broccoli\", \"57: carrot\", \"58: hot dog\", \"59: pizza\", \"60: donut\", \"61: cake\", \"62: chair\", \"63: couch\", \"64: potted plant\", \"65: bed\", \"67: dining table\", \"70: toilet\", \"72: tv\", \"73: laptop\", \"74: mouse\", \"75: remote\", \"76: keyboard\", \"77: cell phone\", \"78: microwave\", \"79: oven\", \"80: toaster\", \"81: sink\", \"82: refrigerator\", \"84: book\", \"85: clock\", \"86: vase\", \"87: scissors\", \"88: teddy bear\", \"89: hair drier\", \"90: toothbrush\"]\n",
    "print(image_path)\n",
    "epochs=3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = adv_model_instance.train_step(np.expand_dims(image_np.copy(),0),target_labels)\n",
    "\n",
    "    \n",
    "    #显示中间结果\n",
    "    if (epoch % 50) == 2:  \n",
    "#         print(\"epoch={} loss={}\".format(epoch,loss))\n",
    "        adv_model_instance.inference_draw(np.expand_dims(image_np.copy(),0))\n",
    "\n",
    "img = image_np.astype(np.int16)#此步是为了避免像素点小于0，大于255的情况\n",
    "mu =0\n",
    "sigma = 20\n",
    "for i in range(img.shape[0]):\n",
    "     for j in range(img.shape[1]):\n",
    "        for k in range(img.shape[2]):\n",
    "            img[i,j,k] = img[i,j,k] +random.gauss(mu=mu,sigma=sigma)\n",
    "img[img>255] = 255\n",
    "img[img<0] = 0\n",
    "img = img.astype(np.uint8)\n",
    "adv_model_instance.inference_draw(np.expand_dims(img,0))\n",
    "\n",
    "\n",
    "# the array based representation of the image will be used later in order to prepare the\n",
    "# result image with boxes and labels on it.\n",
    "\n",
    "# inference_model_instance.inference_draw(np.expand_dims(img,0))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
